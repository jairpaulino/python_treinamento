{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nlp_01_imdb-br.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPSSqKfgZcvhTmf9lK9vJ9o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jairpaulino/python_treinamento/blob/main/nlp_01_imdb_br.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4pAatMBbf-0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a031b14-1aaa-4e99-ad2d-7c420ed290b7"
      },
      "source": [
        "#pip install -U -q PyDrive\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMr6MCktVjuW"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "54i7aggsbtI7",
        "outputId": "ca362b46-983e-451e-ec75-91520828ae47"
      },
      "source": [
        "resenha = pd.read_csv('/content/drive/MyDrive/Doutorado/imdb-reviews-pt-br.csv')\n",
        "resenha.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-60a1cfd0a3d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresenha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Doutorado/imdb-reviews-pt-br.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mresenha\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Doutorado/imdb-reviews-pt-br.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXuLO7NpZQwO"
      },
      "source": [
        "print(resenha.text_pt[189])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXEO06hZZgtO"
      },
      "source": [
        "print(resenha.text_pt[49002])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivwPfb_gZ-9g"
      },
      "source": [
        "print(resenha.sentiment.value_counts())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFQX2xXMaS0P"
      },
      "source": [
        "classificacao = resenha['sentiment'].replace([\"neg\", \"pos\"], [0,1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lp_0CSAPaqDy"
      },
      "source": [
        "resenha[\"classificacao\"] = classificacao\n",
        "resenha.tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wg8ysDmJntOO"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfK3xAyenucD"
      },
      "source": [
        "texto = [\"Assisti um filme ótimo\", \"Assisti ao um Filme ruim\"]\n",
        "\n",
        "vetorizar = CountVectorizer(lowercase = True)\n",
        "bag_of_words = vetorizar.fit_transform(texto)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bs3PrGNRoMVO"
      },
      "source": [
        "vetorizar.get_feature_names()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yrm2qUjKoC-d"
      },
      "source": [
        "matrix_esparsa = pd.DataFrame.sparse.from_spmatrix(bag_of_words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ik9I0L4bpWN6"
      },
      "source": [
        "matrix_esparsa"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlKgzdiOp2Qg"
      },
      "source": [
        "vetorizar = CountVectorizer(lowercase=False, max_features=100)\n",
        "bag_of_words = vetorizar.fit_transform(resenha.text_pt)\n",
        "print(bag_of_words.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SK9eoHvBqWvw"
      },
      "source": [
        "matrix_esparsa = pd.DataFrame.sparse.from_spmatrix(bag_of_words)\n",
        "matrix_esparsa"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qdkEVjLqn0H"
      },
      "source": [
        "treino, teste, classe_treino, classe_teste = train_test_split(bag_of_words,\n",
        "                                                              resenha.classificacao,\n",
        "                                                              random_state = 123)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOhULDgPqqKC"
      },
      "source": [
        "def Classificar_texto(texto, coluna_texto, coluna_classificacao):\n",
        "  vetorizar = CountVectorizer(lowercase=False, max_features=50)\n",
        "  bag_of_words = vetorizar.fit_transform(texto[coluna_texto])\n",
        "\n",
        "  treino, teste, classe_treino, classe_teste = train_test_split(bag_of_words,\n",
        "                                                                texto[coluna_classificacao],\n",
        "                                                                random_state = 123)\n",
        "\n",
        "  rl = LogisticRegression(solver = 'lbfgs')\n",
        "  rl.fit(treino, classe_treino)\n",
        "  return rl.score(teste, classe_teste)\n",
        "\n",
        "print(Classificar_texto(resenha, \"text_pt\", \"classificacao\"))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ye656KkRzc5I"
      },
      "source": [
        "pip install wordcloud"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-r5ALqcyPEE"
      },
      "source": [
        "from wordcloud import WordCloud"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pbJgo60zj6s"
      },
      "source": [
        "todas_palavras = [texto for texto in resenha.text_pt]\n",
        "len(todas_palavras)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUAYsqW70e23"
      },
      "source": [
        "todas_palavras = ' '.join([texto for texto in resenha.text_pt])\n",
        "len(todas_palavras)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lynKJA9l06B_"
      },
      "source": [
        "nuvem_palavras = WordCloud(width=800, \n",
        "                           height=500, \n",
        "                           max_font_size = 110,\n",
        "                           collocations = False).generate(todas_palavras)\n",
        "nuvem_palavras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vN8e_aNh1igY"
      },
      "source": [
        "plt.figure(figsize=(10,7))\n",
        "plt.imshow(nuvem_palavras, interpolation=\"bilinear\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikj_ZGeP6ima"
      },
      "source": [
        "resenha.query(\"sentiment == 'pos'\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vcc9X8jw63dZ"
      },
      "source": [
        "def nuvem_palavras_neg(texto, coluna_texto):\n",
        "  texto_negativo = texto.query(\"sentiment == 'neg'\")\n",
        "  todas_palavras = ' '.join([texto for texto in texto_negativo[coluna_texto]])\n",
        "  len(todas_palavras)\n",
        "  nuvem_palavras = WordCloud(width=800, \n",
        "                            height=500, \n",
        "                            max_font_size = 110,\n",
        "                            collocations = False).generate(todas_palavras)\n",
        "  nuvem_palavras\n",
        "  plt.figure(figsize=(10,7))\n",
        "  plt.imshow(nuvem_palavras, interpolation=\"bilinear\")\n",
        "  plt.axis(\"off\")\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7iqpcD87XdR"
      },
      "source": [
        "def nuvem_palavras_pos(texto, coluna_texto):\n",
        "  texto_positivo = texto.query(\"sentiment == 'pos'\")\n",
        "  todas_palavras = ' '.join([texto for texto in texto_positivo[coluna_texto]])\n",
        "  len(todas_palavras)\n",
        "  nuvem_palavras = WordCloud(width=800, \n",
        "                            height=500, \n",
        "                            max_font_size = 110,\n",
        "                            collocations = False).generate(todas_palavras)\n",
        "  nuvem_palavras\n",
        "  plt.figure(figsize=(10,7))\n",
        "  plt.imshow(nuvem_palavras, interpolation=\"bilinear\")\n",
        "  plt.axis(\"off\")\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EodzTPUK7cCk"
      },
      "source": [
        "nuvem_palavras_neg(resenha, \"text_pt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTTrK2vE7hmv"
      },
      "source": [
        "nuvem_palavras_pos(resenha, \"text_pt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngToA17LdUr8"
      },
      "source": [
        "import nltk\n",
        "#nltk.download() #nltk.download(\"all\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hz7kKFYidm_v"
      },
      "source": [
        "frase = [\"Um filme ruim\", \"um filme bom\"]\n",
        "frequencia = nltk.FreqDist(frase)\n",
        "frequencia"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZNAnG6ReGDn"
      },
      "source": [
        "# Separação por espaço em branco\n",
        "from nltk import tokenize\n",
        "frase = \"Bem vindo ao mundo do PNL\"\n",
        "token_espaço = tokenize.WhitespaceTokenizer()\n",
        "token_frase = token_espaço.tokenize(frase)\n",
        "token_frase"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NeGjv1uEeDFr"
      },
      "source": [
        "token_frase = token_espaço.tokenize(todas_palavras)\n",
        "frequencia = nltk.FreqDist(token_frase)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YVWC6rif7gN"
      },
      "source": [
        "df_frequencia = pd.DataFrame({\"Palavra\": list(frequencia.keys()),\n",
        "                              \"Frequência\": list(frequencia.values())})\n",
        "df_frequencia.nlargest(columns=\"Frequência\", n = 10)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XyR4udCPjors"
      },
      "source": [
        "import seaborn as sns\n",
        "\n",
        "\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "ax = sns.barplot(data=df_frequencia.nlargest(columns=\"Frequência\", n=10), \n",
        "                 x=\"Palavra\", y=\"Frequência\", color='gray')\n",
        "ax.set(ylabel = \"Contagem\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LwSC0Khmil9"
      },
      "source": [
        "def pareto(texto, coluna_texto, quantidade):\n",
        "    todas_palavras = ' '.join([texto for texto in texto[coluna_texto]])\n",
        "    token_frase = token_espaco.tokenize(todas_palavras)\n",
        "    frequencia = nltk.FreqDist(token_frase)\n",
        "    df_frequencia = pd.DataFrame({\"Palavra\": list(frequencia.keys()),\n",
        "                                   \"Frequência\": list(frequencia.values())})\n",
        "    df_frequencia = df_frequencia.nlargest(columns = \"Frequência\", n = quantidade)\n",
        "    plt.figure(figsize=(12,8))\n",
        "    ax = sns.barplot(data = df_frequencia, x = \"Palavra\", y = \"Frequência\", color = 'gray')\n",
        "    ax.set(ylabel = \"Contagem\")\n",
        "    plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvqjbSgLnYnq"
      },
      "source": [
        "pareto(resenha, \"text_pt\", 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Fyf45wCpyFP"
      },
      "source": [
        "import nltk"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWKWbBOEph16"
      },
      "source": [
        "palavras_irrelevantes = nltk.corpus.stopwords.words(\"portuguese\")\n",
        "palavras_irrelevantes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bj2L96SjqBeC"
      },
      "source": [
        "frase_processada = list()\n",
        "token_espaco = tokenize.WhitespaceTokenizer()\n",
        "\n",
        "for opiniao in resenha.text_pt:\n",
        "  nova_frase = list()\n",
        "  palavras_texto = token_espaco.tokenize(opiniao)\n",
        "  for palavra in palavras_texto:\n",
        "    if palavra not in palavras_irrelevantes:\n",
        "      nova_frase.append(palavra)\n",
        "  frase_processada.append(' '.join(nova_frase))\n",
        "\n",
        "resenha[\"tratamento_1\"] = frase_processada"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBCpLbkWrxwr"
      },
      "source": [
        "resenha.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dX3-T1TsLNP"
      },
      "source": [
        "Classificar_texto(resenha, \"tratamento_1\", \"classificacao\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYi1tOTvsyVz"
      },
      "source": [
        "pareto(resenha.query(\"sentiment == 'pos'\"), \"tratamento_1\", 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rysWURm6TrIu"
      },
      "source": [
        "from nltk import tokenize\n",
        "frase = \"Os cursos da Alura são ótimos, além de ótimos, têm alunos ótimos!\"\n",
        "token_espaco = tokenize.WhitespaceTokenizer()\n",
        "token_pontuacao = tokenize.WordPunctTokenizer()\n",
        "\n",
        "token_1 = token_espaco.tokenize(frase)\n",
        "token_2 = token_pontuacao.tokenize(frase)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxjkUquqUAWq"
      },
      "source": [
        "from string import punctuation\n",
        "pontuacao = list()\n",
        "for ponto in punctuation:\n",
        "  pontuacao.append(ponto)\n",
        "\n",
        "pontuacao"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shkiJft5Uhm3"
      },
      "source": [
        "pontuacao_stopwords = pontuacao + palavras_irrelevantes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnUDnNWGUnhK"
      },
      "source": [
        "frase_processada = list()\n",
        "for opiniao in resenha[\"tratamento_1\"]:\n",
        "  nova_frase = list()\n",
        "  palavras_texto = token_pontuacao.tokenize(opiniao)\n",
        "  for palavra in palavras_texto:\n",
        "    if palavra not in pontuacao_stopwords:\n",
        "      nova_frase.append(palavra)\n",
        "  frase_processada.append(' '.join(nova_frase))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpPUKx7rVlcN"
      },
      "source": [
        "resenha[\"tratamento_2\"] = frase_processada\n",
        "resenha.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTLOfujFV3ws"
      },
      "source": [
        "pareto(resenha, \"tratamento_2\", 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gt5Ocw4kWo0I"
      },
      "source": [
        "#pip install unidecode \n",
        "import unidecode"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDCNbItuXA3H"
      },
      "source": [
        "sem_acentos = [unidecode.unidecode(texto) for texto in resenha['tratamento_2']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdHpUZ2AXM0K"
      },
      "source": [
        "sem_acentos[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWQnJS9LX5ap"
      },
      "source": [
        "stopwords_sem_acentos = [unidecode.unidecode(texto) for texto in pontuacao_stopwords]\n",
        "stopwords_sem_acentos"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IED_CYjmYR6l"
      },
      "source": [
        "frase_processada = list()\n",
        "for opiniao in resenha[\"tratamento_2\"]:\n",
        "  nova_frase = list()\n",
        "  palavras_texto = token_pontuacao.tokenize(opiniao)\n",
        "  for palavra in palavras_texto:\n",
        "    if palavra not in pontuacao_stopwords:\n",
        "      nova_frase.append(palavra)\n",
        "  frase_processada.append(' '.join(nova_frase))\n",
        "\n",
        "resenha[\"tratamento_3\"] = frase_processada"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kWKJ2pdYpg2"
      },
      "source": [
        "resenha.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suj0sDe2YuI1"
      },
      "source": [
        "acc_tratamento_3 = Classificar_texto(resenha, \"tratamento_3\", \"classificacao\")\n",
        "acc_tratamento_3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJIlU_ouZCM8"
      },
      "source": [
        "nuvem_palavras_neg(resenha, \"tratamento_3\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6aiGb6cZRLO"
      },
      "source": [
        "nuvem_palavras_pos(resenha, \"tratamento_3\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uq79oowVZJQy"
      },
      "source": [
        "pareto(resenha, \"tratamento_3\", 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6kUrtsXIZzWR"
      },
      "source": [
        "frase_processada = list()\n",
        "for opiniao in resenha[\"tratamento_3\"]:\n",
        "  nova_frase = list()\n",
        "  opiniao = opiniao.lower()\n",
        "  palavras_texto = token_pontuacao.tokenize(opiniao)\n",
        "  for palavra in palavras_texto:\n",
        "    if palavra not in stopwords_sem_acentos:\n",
        "      nova_frase.append(palavra)\n",
        "  frase_processada.append(' '.join(nova_frase))\n",
        "\n",
        "resenha[\"tratamento_4\"] = frase_processada"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuSraYWXabuO"
      },
      "source": [
        "resenha[\"text_pt\"][0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XA4usoi4alB6"
      },
      "source": [
        "resenha[\"tratamento_4\"][0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6WTtUN7avsf"
      },
      "source": [
        "pareto(resenha, \"tratamento_4\", 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDhNNA0Ca6lz"
      },
      "source": [
        "acc_tratamento_4 = Classificar_texto(resenha, \"tratamento_4\", \"classificacao\")\n",
        "acc_tratamento_4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2bnmBQibMu7"
      },
      "source": [
        "nuvem_palavras_neg(resenha, \"tratamento_4\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7cMm0CJbRmp"
      },
      "source": [
        "nuvem_palavras_pos(resenha, \"tratamento_4\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r45G5pZBcQKo"
      },
      "source": [
        "resenha[\"text_pt\"][0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIE1cBwNcGcl"
      },
      "source": [
        "resenha[\"tratamento_1\"][0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gRGsSQfcbAj"
      },
      "source": [
        "resenha[\"tratamento_2\"][0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nl2GPfoncjwv"
      },
      "source": [
        "resenha[\"tratamento_4\"][0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oF6mX6nxdM5q"
      },
      "source": [
        "stemmer = nltk.RSLPStemmer()\n",
        "stemmer.stem(\"correria\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnqicDXqdsOU"
      },
      "source": [
        "frase_processada = list()\n",
        "for opiniao in resenha[\"tratamento_4\"]:\n",
        "  nova_frase = list()\n",
        "  palavras_texto = token_pontuacao.tokenize(opiniao)\n",
        "  for palavra in palavras_texto:\n",
        "    if palavra not in stopwords_sem_acentos:\n",
        "      nova_frase.append(stemmer.stem(palavra))\n",
        "  frase_processada.append(' '.join(nova_frase))\n",
        "\n",
        "resenha[\"tratamento_5\"] = frase_processada"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2SrJFE-sd8rt"
      },
      "source": [
        "acc_tratamento_5 = Classificar_texto(resenha, \"tratamento_5\", \"classificacao\")\n",
        "acc_tratamento_5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlX3eCyVehsz"
      },
      "source": [
        "pareto(resenha, \"tratamento_5\", 10)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}